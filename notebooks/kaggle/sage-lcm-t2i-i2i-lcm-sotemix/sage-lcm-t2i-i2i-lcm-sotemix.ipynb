{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13924198,"sourceType":"datasetVersion","datasetId":8807372}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, sys\n\np = \"/kaggle/input/sage-zrok-token/.zrok_api_key\"\nzrok_token = None\n\nif os.path.isfile(p):\n    with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        zrok_token = f.read().strip()\n\nif not zrok_token:\n    print(\"❌ Token not found or empty:\", p)\n    sys.exit(1)","metadata":{"id":"TGpuwht5AhBy","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"FCPk45x-AhB3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\nprint(\"Setting up model...\")\n\n# --- Copy LCM SoteMix if not already present ---\nsource = \"/kaggle/input/lcm-sotemix\"\ndest = \"/kaggle/working/Disty0/LCM_SoteMix\"\n\nif os.path.exists(dest):\n    print(f\"✓ LCM SoteMix already exists at {dest}, skipping copy\")\nelse:\n    # Ensure the parent directory of the destination exists\n    os.makedirs(os.path.dirname(dest), exist_ok=True)\n    print(f\"  Copying LCM SoteMix... (this may take a moment)\")\n    shutil.copytree(source, dest)\n    print(f\"  ✓ Copied to {dest}\")\n\nprint(\"✅ Model ready!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------------\n# TXT2IMG + LCM pipeline\n# ----------------------------\nimport torch\nfrom diffusers import AutoPipelineForText2Image, LCMScheduler\n\n# --- Configuration ---\n# The model will be loaded from a local Kaggle dataset path.\n# This path should correspond to the dataset you create containing the 'Disty0/LCM_SoteMix' model files.\nMODEL_PATH = '/kaggle/working/Disty0/LCM_SoteMix'\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Loading Text-to-Image pipeline from local path: {MODEL_PATH}\")\n\n# --- Load the pipeline from the local dataset path ---\npipe_txt2img = AutoPipelineForText2Image.from_pretrained(\n    MODEL_PATH,\n    torch_dtype=torch.float16\n)\n\n# --- Set the LCM Scheduler ---\npipe_txt2img.scheduler = LCMScheduler.from_config(pipe_txt2img.scheduler.config)\n\n# --- Move to device and disable safety checker ---\npipe_txt2img = pipe_txt2img.to(device)\npipe_txt2img.safety_checker = lambda images, clip_input=None: (images, [False] * len(images))\n\nprint(\"✅ Text-to-Image pipeline is ready!\")","metadata":{"id":"Z5Kv4Re0AhB7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Q4dLMo2FlOrI","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ----------------------\n# IMG2IMG + LCM pipeline\n# ----------------------\nimport torch\nfrom diffusers import AutoPipelineForImage2Image, LCMScheduler\n\n# --- Configuration ---\n# The model will be loaded from a local Kaggle dataset path.\n# This path should correspond to the dataset you create containing the 'Disty0/LCM_SoteMix' model files.\nMODEL_PATH = '/kaggle/working/Disty0/LCM_SoteMix'\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(f\"Loading Image-to-Image pipeline from local path: {MODEL_PATH}\")\n\n# --- Load the pipeline from the local dataset path ---\npipe_img2img = AutoPipelineForImage2Image.from_pretrained(\n    MODEL_PATH,\n    torch_dtype=torch.float16\n)\n\n# --- Set the LCM Scheduler ---\npipe_img2img.scheduler = LCMScheduler.from_config(pipe_img2img.scheduler.config)\n\n# --- Move to device and disable safety checker ---\npipe_img2img = pipe_img2img.to(device)\npipe_img2img.safety_checker = lambda images, clip_input=None: (images, [False] * len(images))\n\nprint(\"✅ Image-to-Image pipeline is ready!\")","metadata":{"id":"KQRP8RUElO0r","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"ekaJZWL91sC3","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"eflsIfQ_1pvY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"3rSY9im-1p3U","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tRT5sgp4mwOC","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# -----------------------------\n# METHOD text-to-image generator\n# (returns PIL.Image for easy FastAPI integration)\n# -----------------------------\n\nfrom datetime import datetime\nfrom IPython.display import display\nimport torch\nimport io\nimport os\n\ndef generate_txt2img(\n    pipe_txt2img,\n    prompt,\n    negative_prompt=None,\n    seed=None,\n    num_inference_steps=4,\n    guidance_scale=1.0,\n    height=768,\n    width=768,\n    device=None\n):\n    \"\"\"\n    Generate an image with `pipe_txt2img` and return a PIL.Image (does not save by default).\n    If save=True it will write a PNG to disk but still return the PIL.Image.\n    If return_metadata=True it returns (image, metadata_dict).\n    \"\"\"\n    # device detection\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # choose seed\n    if seed is None:\n        seed = int(torch.randint(0, 2**31 - 1, (1,)).item())\n\n    # create generator for the chosen device (fallback to CPU if unsupported)\n    try:\n        gen = torch.Generator(device=device).manual_seed(seed)\n    except Exception:\n        gen = torch.Generator().manual_seed(seed)\n\n    # build call kwargs\n    call_kwargs = {\n        \"prompt\": prompt,\n        \"num_inference_steps\": int(num_inference_steps),\n        \"guidance_scale\": float(guidance_scale),\n        \"generator\": gen,\n    }\n    if negative_prompt is not None:\n        call_kwargs[\"negative_prompt\"] = negative_prompt\n    if height is not None:\n        call_kwargs[\"height\"] = int(height)\n    if width is not None:\n        call_kwargs[\"width\"] = int(width)\n\n\n    # call the pipeline\n    pipeline_output = pipe_txt2img(**call_kwargs)\n\n    # extract image (typical diffusers output)\n    try:\n        image = pipeline_output.images[0]\n    except Exception:\n        image = pipeline_output[0]\n\n\n    return image","metadata":{"id":"CD7PUqlaYs3M","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"UpmYywyLmwVI","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"big7nGpMAhCG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"Feeq_9AclPOi","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------------------------- #\n# Reusable img2img generator (SDXL + LCM)\n# ------------------------------------- #\nimport torch\nimport random\n\ndef generate_img2img(\n    pipe_img2img,\n    prompt,\n    init_image,\n    negative_prompt=None,\n    strength=0.8,\n    guidance_scale=1.0,\n    num_inference_steps=4,\n    seed=None,\n    dtype=torch.float16,\n    device=None\n):\n    \"\"\"\n    Generate an image with `pipe_img2img` and return a PIL.Image (does not save by default).\n    Designed for SDXL + LCM LoRA pipelines.\n    \"\"\"\n\n    # --- Device detection ---\n    if device is None:\n        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # --- Seed handling ---\n    if seed is None:\n        seed = int(torch.randint(0, 2**31 - 1, (1,)).item())\n\n    try:\n        generator = torch.Generator(device=device).manual_seed(seed)\n    except Exception:\n        generator = torch.Generator().manual_seed(seed)\n\n    # --- Build call kwargs ---\n    call_kwargs = {\n        \"prompt\": prompt,\n        \"image\": init_image,\n        \"strength\": float(strength),\n        \"guidance_scale\": float(guidance_scale),\n        \"num_inference_steps\": int(num_inference_steps),\n        \"generator\": generator,\n    }\n    if negative_prompt is not None:\n        call_kwargs[\"negative_prompt\"] = negative_prompt\n\n    # --- Run pipeline ---\n    with torch.inference_mode(), torch.autocast(device, dtype=dtype):\n        pipeline_output = pipe_img2img(**call_kwargs)\n\n    # --- Extract result ---\n    try:\n        image = pipeline_output.images[0]\n    except Exception:\n        image = pipeline_output[0]\n\n    return image","metadata":{"id":"Ho5lX0jElPUG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"I7p5hf2ohk3z","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"qShlMxGxoH8C","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"nOacxIfIYtTn","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --------------------------\n# FastAPI app init\n# --------------------------\n\nfrom fastapi import FastAPI\nimport nest_asyncio\nimport uvicorn\n\n# Assume generate_txt2img, generate_img2img, pipe_txt2img, pipe_img2img are already defined\napp = FastAPI()\nnest_asyncio.apply()  # allow running uvicorn in Colab\n#print(\"FastAPI app initialized.\")","metadata":{"id":"NW9bWcz7Ytan","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"iQp-O3NNYtxG","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"V08PrK5sNpyz","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# ---------------------------\n# Unified T2I/I2I endpoint /generate (SDXL + LCM LoRA)\n# ---------------------------\n\nfrom fastapi import Form, UploadFile, File\nfrom fastapi.responses import StreamingResponse, JSONResponse\nfrom io import BytesIO\nfrom PIL import Image\n\n@app.post(\"/generate\")\nasync def generate(\n    prompt: str = Form(...),\n    negative_prompt: str = Form(None),\n    height: int = Form(768),\n    width: int = Form(768),\n    num_inference_steps: int = Form(4),       # LCM default low steps\n    guidance_scale: float = Form(1.0),        # LCM default guidance\n    seed: int = Form(None),\n\n    # img2img-only params\n    strength: float = Form(0.8),\n    init_image: UploadFile = File(None),      # optional: if present → img2img\n):\n    \"\"\"Unified endpoint: txt2img if no init_image, img2img if init_image provided.\"\"\"\n\n    # --- Img2img path ---\n    if init_image is not None:\n        try:\n            init_img = Image.open(BytesIO(await init_image.read())).convert(\"RGB\")\n        except Exception as e:\n            return JSONResponse(\n                status_code=400,\n                content={\"error\": f\"Failed to read init_image: {str(e)}\"},\n            )\n\n        try:\n            generated_image = generate_img2img(\n                pipe_img2img,\n                prompt=prompt,\n                negative_prompt=negative_prompt,\n                init_image=init_img,\n                strength=strength,\n                guidance_scale=guidance_scale,\n                num_inference_steps=num_inference_steps,\n                seed=seed,\n            )\n        except Exception as e:\n            return JSONResponse(status_code=500, content={\"error\": str(e)})\n\n    # --- Txt2img path ---\n    else:\n        try:\n            generated_image = generate_txt2img(\n                pipe_txt2img,\n                prompt=prompt,\n                negative_prompt=negative_prompt,\n                height=height,\n                width=width,\n                num_inference_steps=num_inference_steps,\n                guidance_scale=guidance_scale,\n                seed=seed,\n            )\n        except Exception as e:\n            return JSONResponse(status_code=500, content={\"error\": str(e)})\n\n    # --- Return PNG stream ---\n    buffer = BytesIO()\n    generated_image.save(buffer, format=\"PNG\")\n    buffer.seek(0)\n    return StreamingResponse(buffer, media_type=\"image/png\")","metadata":{"id":"0CizW9kdpPEX","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tEUishJUpPMU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"J0TcZRUppPQY","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"DQKtR6TxO-Ts","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download zrok v1.1.3 (latest)\n!wget https://github.com/openziti/zrok/releases/download/v1.1.3/zrok_1.1.3_linux_amd64.tar.gz\n!tar -xzf zrok_1.1.3_linux_amd64.tar.gz\n!chmod +x zrok","metadata":{"id":"eO81fsViO-Ye","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enable (automatic migration from 0.4)\n!./zrok enable --headless \"$zrok_token\"\n\n# Use the agent for better process management\n#!./zrok agent start &\n#!./zrok share public localhost:8000 --headless","metadata":{"id":"3XGpCMjFO-bc","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!./zrok disable","metadata":{"id":"qvl2xM3pO-d0","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import uvicorn\nimport threading\n\ndef run_uvicorn():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n\n# Start in background thread\nthreading.Thread(target=run_uvicorn, daemon=True).start()","metadata":{"id":"pHH-93euO-ri","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport re\nimport time\n\ndef start_zrok_tunnel(port=8000):\n    # Start the tunnel\n    process = subprocess.Popen([\n        \"./zrok\", \"share\", \"public\", f\"localhost:{port}\", \"--headless\"\n    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n\n    # Give it a moment to start\n    time.sleep(3)\n\n    # Check agent status to get the URL\n    status_process = subprocess.run([\n        \"./zrok\", \"agent\", \"status\"\n    ], capture_output=True, text=True)\n\n    print(\"Agent Status:\")\n    print(status_process.stdout)\n\n    return process\n\n# Start the tunnel\ntunnel_process = start_zrok_tunnel(8000)\nprint(\"Zrok tunnel started! Check the agent status above for your public URL.\")","metadata":{"id":"jWt8d9UqO-vU","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"k5vT7HsOQIA7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!./zrok overview","metadata":{"id":"tAXFNNnpNqf7","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"qqAO1R_kQIGK","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"tZkjBnCpjyRF","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nprint(\"Server and zrok tunnel are running. Keeping the notebook alive...\")\n\ntry:\n    while True:\n        time.sleep(60)\nexcept KeyboardInterrupt:\n    print(\"Shutting down.\")","metadata":{"id":"_vupHXeDjyVf","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"2cHyLENtQIVw","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"XsF3SWhNkqN_","trusted":true},"outputs":[],"execution_count":null}]}