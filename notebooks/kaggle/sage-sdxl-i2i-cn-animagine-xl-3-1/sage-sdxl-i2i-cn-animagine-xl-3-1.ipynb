{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.13"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[{"sourceId":13924198,"sourceType":"datasetVersion","datasetId":8807372},{"sourceId":13950321,"sourceType":"datasetVersion","datasetId":8891751},{"sourceId":13972469,"sourceType":"datasetVersion","datasetId":8907734}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------------------------------------------------------------------\n# CONFIGURATION CELL\n# ---------------------------------------------------------------------------\n# Set to True to load the Img2Img pipeline, False for the Txt2Img pipeline.\n# This is the ONLY cell you need to change between your two notebook copies.\n\nUSE_IMG2IMG = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:45:25.840132Z","iopub.execute_input":"2025-12-03T21:45:25.840439Z","iopub.status.idle":"2025-12-03T21:45:25.844092Z","shell.execute_reply.started":"2025-12-03T21:45:25.840414Z","shell.execute_reply":"2025-12-03T21:45:25.843420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, sys\n\np = \"/kaggle/input/sage-zrok-token/.zrok_api_key\"\nzrok_token = None\n\nif os.path.isfile(p):\n    with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n        zrok_token = f.read().strip()\n\nif not zrok_token:\n    print(\"❌ Token not found or empty:\", p)\n    sys.exit(1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:45:28.803554Z","iopub.execute_input":"2025-12-03T21:45:28.804024Z","iopub.status.idle":"2025-12-03T21:45:28.812766Z","shell.execute_reply.started":"2025-12-03T21:45:28.803999Z","shell.execute_reply":"2025-12-03T21:45:28.812088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\n\nprint(\"Setting up models...\")\n\n# --- Copy Animagine-XL 3.1 if not already present ---\nsource = \"/kaggle/input/animagine-xl-3-1\"\ndest = \"/kaggle/working/cagliostrolab/animagine-xl-3.1\"\n\nif os.path.exists(dest):\n    print(f\"✓ Animagine-XL v3.1 already exists at {dest}, skipping copy\")\nelse:\n    print(f\"  Copying Animagine-XL v3.1... (this may take a moment)\")\n    shutil.copytree(source, dest)\n    print(f\"  ✓ Copied to {dest}\")\n\n# --- Copy ControlNet OpenPose for SDXL if not already present ---\ncontrolnet_source = \"/kaggle/input/controlnet-openpose-sdxl\"\ncontrolnet_dest = \"/kaggle/working/controlnet-openpose-sdxl\"\n\nif os.path.exists(controlnet_dest):\n    print(f\"✓ ControlNet OpenPose SDXL already exists at {controlnet_dest}, skipping copy\")\nelse:\n    print(f\"  Copying ControlNet OpenPose SDXL...\")\n    shutil.copytree(controlnet_source, controlnet_dest)\n    print(f\"  ✓ Copied to {controlnet_dest}\")\n\nprint(\"✅ All models ready!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:45:32.498188Z","iopub.execute_input":"2025-12-03T21:45:32.498482Z","iopub.status.idle":"2025-12-03T21:47:18.101970Z","shell.execute_reply.started":"2025-12-03T21:45:32.498461Z","shell.execute_reply":"2025-12-03T21:47:18.101202Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom diffusers import (\n    ControlNetModel,\n    StableDiffusionXLControlNetPipeline,\n    StableDiffusionXLControlNetImg2ImgPipeline,\n    DPMSolverMultistepScheduler\n)\n\n# --- Device ---\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# --- Model paths ---\nlocal_model_path = \"/kaggle/working/cagliostrolab/animagine-xl-3.1\"\nlocal_controlnet_path = \"/kaggle/working/controlnet-openpose-sdxl\"\n\n# --- Load ControlNet (common for both pipelines) ---\nprint(\"Loading ControlNet model...\")\ncontrolnet = ControlNetModel.from_pretrained(\n    local_controlnet_path,\n    torch_dtype=torch.float16\n).to(device)\nprint(\"✓ ControlNet loaded.\")\n\npipe = None\n\n# --- Conditionally load the main pipeline based on the USE_IMG2IMG flag ---\nif not USE_IMG2IMG:\n    print(\"Mode: Txt2Img. Loading pipeline...\")\n    pipe = StableDiffusionXLControlNetPipeline.from_pretrained(\n        local_model_path,\n        controlnet=controlnet,\n        torch_dtype=torch.float16\n        #variant=\"fp16\"\n    ).to(device)\n    print(\"✓ Txt2Img pipeline with ControlNet loaded.\")\nelse:\n    print(\"Mode: Img2Img. Loading pipeline...\")\n    pipe = StableDiffusionXLControlNetImg2ImgPipeline.from_pretrained(\n        local_model_path,\n        controlnet=controlnet,\n        torch_dtype=torch.float16\n        #variant=\"fp16\"\n    ).to(device)\n    print(\"✓ Img2Img pipeline with ControlNet loaded.\")\n\n# --- Configure Scheduler and Safety Checker ---\npipe.scheduler = DPMSolverMultistepScheduler.from_config(\n    pipe.scheduler.config,\n    algorithm_type=\"sde-dpmsolver++\"\n)\npipe.safety_checker = lambda images, clip_input=None: (images, [False] * len(images))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:47:21.171342Z","iopub.execute_input":"2025-12-03T21:47:21.172343Z","iopub.status.idle":"2025-12-03T21:47:56.581316Z","shell.execute_reply.started":"2025-12-03T21:47:21.172317Z","shell.execute_reply":"2025-12-03T21:47:56.580620Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport torch\nfrom typing import Optional\nimport random\n\n# THIS FUNCTION IS A MODIFIED COPY FROM THE WORKING `sage-t2i-counterfeit-xl-25` NOTEBOOK\ndef generate_txt2img_xl(\n    pipe, # StableDiffusionXLControlNetPipeline\n    prompt: str,\n    negative_prompt: Optional[str] = None,\n    height: int = 1024,\n    width: int = 1024,\n    num_inference_steps: int = 40,\n    guidance_scale: float = 7.5,\n    seed: Optional[int] = None,\n    control_image: Optional[Image.Image] = None,\n    controlnet_scale: float = 0.5,\n):\n    \"\"\"\n    Generate an image using the exact same logic structure as the working SDXL notebook.\n    \"\"\"\n    # Choose seed (identical logic)\n    if seed is None:\n        seed = int(torch.randint(0, 2**31 - 1, (1,)).item())\n\n    # Create generator (identical logic)\n    gen = torch.Generator(device=\"cuda\").manual_seed(seed)\n\n    # Determine if ControlNet is active\n    use_controlnet = control_image is not None\n    \n    # The control image for the pipeline must be passed via the 'image' parameter.\n    # If not using ControlNet, we pass a dummy black image to satisfy the pipeline's requirement.\n    pipeline_image = control_image if use_controlnet else Image.new(\"RGB\", (width, height), (0, 0, 0))\n\n    # Build call kwargs (identical structure)\n    call_kwargs = {\n        \"prompt\": prompt,\n        \"negative_prompt\": negative_prompt,\n        \"image\": pipeline_image, # This is the control image for this pipeline\n        \"height\": height,\n        \"width\": width,\n        \"num_inference_steps\": num_inference_steps,\n        \"guidance_scale\": guidance_scale,\n        \"controlnet_conditioning_scale\": controlnet_scale if use_controlnet else 0.0,\n        \"generator\": gen,\n    }\n\n    # Call the pipeline (identical logic)\n    pipeline_output = pipe(**call_kwargs)\n\n    # Extract image (identical logic)\n    image = pipeline_output.images[0]\n\n    return image\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:02.749503Z","iopub.execute_input":"2025-12-03T21:48:02.749798Z","iopub.status.idle":"2025-12-03T21:48:02.756278Z","shell.execute_reply.started":"2025-12-03T21:48:02.749778Z","shell.execute_reply":"2025-12-03T21:48:02.755738Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport torch\nfrom typing import Optional, Tuple\n\ndef _ensure_rgb(img: Image.Image) -> Image.Image:\n    if img.mode != \"RGB\":\n        return img.convert(\"RGB\")\n    return img\n\ndef _resize_control_to_init(control: Image.Image, init: Image.Image, use_nearest: bool = True) -> Image.Image:\n    \"\"\"\n    Resize control image to match init image's size.\n    use_nearest: True for segmentation/pose/edges (preserve labels), False for photos.\n    \"\"\"\n    if control.size == init.size:\n        return control\n    resample = Image.NEAREST if use_nearest else Image.BICUBIC\n    return control.resize(init.size, resample=resample)\n\ndef _pad_to_multiple(img: Image.Image, mult: int = 8, fill=(0,0,0)) -> Image.Image:\n    w, h = img.size\n    new_w = ((w + mult - 1) // mult) * mult\n    new_h = ((h + mult - 1) // mult) * mult\n    if new_w == w and new_h == h:\n        return img\n    new_img = Image.new(img.mode, (new_w, new_h), fill)\n    # paste at top-left (0,0). If you prefer centered, compute offsets.\n    new_img.paste(img, (0, 0))\n    return new_img\n\ndef generate_img2img_xl(\n    pipe,\n    prompt: str,\n    init_image: Image.Image,\n    negative_prompt: Optional[str] = None,\n    strength: float = 0.7,\n    num_inference_steps: int = 40,\n    guidance_scale: float = 7.5,\n    seed: Optional[int] = None,\n    control_image: Optional[Image.Image] = None,\n    controlnet_scale: float = 0.5,\n    control_is_map: bool = True,        # <-- set True for pose/edge/seg maps; False for photos\n    divisible_by: int = 8,              # make sizes multiples of this (8 is typical)\n):\n    \"\"\"\n    Improved handling for control images: ensures same size and divisibility.\n    \"\"\"\n    if seed is None:\n        seed = int(torch.randint(0, 2**31 - 1, (1,)).item())\n    gen = torch.Generator(device=\"cuda\").manual_seed(seed)\n\n    # Ensure RGB\n    init_image = _ensure_rgb(init_image)\n    pipeline_control_image = None\n    use_controlnet = control_image is not None\n\n    if use_controlnet:\n        control_image = _ensure_rgb(control_image)\n        # Resize control to match init image size (preserve labels if control_is_map)\n        if control_image.size != init_image.size:\n            print(f\"[debug] control image size {control_image.size} != init image size {init_image.size}, resizing control -> init\")\n            control_image = _resize_control_to_init(control_image, init_image, use_nearest=control_is_map)\n\n        # Optional: if either dimension is not divisible_by, pad both to same divisible size\n        w_init, h_init = init_image.size\n        new_w = ((w_init + divisible_by - 1) // divisible_by) * divisible_by\n        new_h = ((h_init + divisible_by - 1) // divisible_by) * divisible_by\n        if (new_w, new_h) != (w_init, h_init):\n            print(f\"[debug] padding images from {(w_init,h_init)} -> {(new_w,new_h)} to satisfy divisible_by={divisible_by}\")\n            init_image = _pad_to_multiple(init_image, mult=divisible_by, fill=(0,0,0))\n            control_image = _pad_to_multiple(control_image, mult=divisible_by, fill=(0,0,0))\n\n        pipeline_control_image = control_image\n    else:\n        # Create a black control image matching the init image, padded if needed\n        w_init, h_init = init_image.size\n        new_w = ((w_init + divisible_by - 1) // divisible_by) * divisible_by\n        new_h = ((h_init + divisible_by - 1) // divisible_by) * divisible_by\n        init_image = _pad_to_multiple(init_image, mult=divisible_by, fill=(0,0,0))\n        pipeline_control_image = Image.new(\"RGB\", init_image.size, (0, 0, 0))\n\n    # Debug sizes\n    print(f\"[debug] final init image size: {init_image.size}, control image size: {pipeline_control_image.size}\")\n\n    call_kwargs = {\n        \"prompt\": prompt,\n        \"negative_prompt\": negative_prompt,\n        \"image\": init_image,\n        \"control_image\": pipeline_control_image,\n        \"strength\": strength,\n        \"num_inference_steps\": num_inference_steps,\n        \"guidance_scale\": guidance_scale,\n        \"controlnet_conditioning_scale\": controlnet_scale if use_controlnet else 0.0,\n        \"generator\": gen,\n    }\n\n    pipeline_output = pipe(**call_kwargs)\n    image = pipeline_output.images[0]\n    return image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T22:25:38.138285Z","iopub.execute_input":"2025-12-03T22:25:38.138588Z","iopub.status.idle":"2025-12-03T22:25:38.150595Z","shell.execute_reply.started":"2025-12-03T22:25:38.138566Z","shell.execute_reply":"2025-12-03T22:25:38.149809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastapi import FastAPI\nimport nest_asyncio\nimport uvicorn\n\napp = FastAPI()\nnest_asyncio.apply()  # allow running uvicorn in a notebook","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:11.211924Z","iopub.execute_input":"2025-12-03T21:48:11.212715Z","iopub.status.idle":"2025-12-03T21:48:11.915985Z","shell.execute_reply.started":"2025-12-03T21:48:11.212687Z","shell.execute_reply":"2025-12-03T21:48:11.915410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===================================================================\n# ASYNCHRONOUS TASK HANDLING SETUP\n# ===================================================================\nfrom fastapi import BackgroundTasks, HTTPException, Response\nimport uuid\nimport io\nimport time\nfrom PIL import Image\nimport traceback\n\n# In-memory \"database\" to store task status and results.\n# This is perfect for a single-instance Kaggle notebook.\n# Format: { \"task_id\": {\"status\": \"...\", \"result\": ..., \"error\": ...} }\ntasks = {}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:17.053135Z","iopub.execute_input":"2025-12-03T21:48:17.053876Z","iopub.status.idle":"2025-12-03T21:48:17.058299Z","shell.execute_reply.started":"2025-12-03T21:48:17.053850Z","shell.execute_reply":"2025-12-03T21:48:17.057263Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from PIL import Image\nimport io\nimport traceback\n\ndef run_generation_task(task_id: str, params: dict):\n    \"\"\"\n    Performs the heavy lifting of image generation, updating the global `tasks` dict.\n    \"\"\"\n    try:\n        tasks[task_id][\"status\"] = \"PROCESSING\"\n\n        # Re-create PIL images from bytes if they exist\n        init_img_bytes = params.pop(\"init_image_bytes\", None)\n        control_img_bytes = params.pop(\"control_image_bytes\", None)\n        \n        init_image = Image.open(io.BytesIO(init_img_bytes)).convert(\"RGB\") if init_img_bytes else None\n        control_image = Image.open(io.BytesIO(control_img_bytes)).convert(\"RGB\") if control_img_bytes else None\n\n        # Call the appropriate generation function\n        if init_image:\n            # Img2Img workflow\n            generated_image = generate_img2img_xl(\n                pipe=pipe,\n                init_image=init_image,\n                control_image=control_image,\n                prompt=params[\"prompt\"],\n                negative_prompt=params[\"negative_prompt\"],\n                strength=params[\"strength\"],\n                num_inference_steps=params[\"num_inference_steps\"],\n                guidance_scale=params[\"guidance_scale\"],\n                seed=params[\"seed\"],\n                controlnet_scale=params.get(\"controlnet_scale\", 0.5)\n            )\n        else:\n            # Txt2Img workflow\n            generated_image = generate_txt2img_xl(\n                pipe=pipe,\n                control_image=control_image,\n                prompt=params[\"prompt\"],\n                negative_prompt=params[\"negative_prompt\"],\n                height=params[\"height\"],\n                width=params[\"width\"],\n                num_inference_steps=params[\"num_inference_steps\"],\n                guidance_scale=params[\"guidance_scale\"],\n                seed=params[\"seed\"],\n                controlnet_scale=params.get(\"controlnet_scale\", 0.5)\n            )\n            \n        # Process and store the result\n        if generated_image.mode != 'RGB':\n            generated_image = generated_image.convert(\"RGB\")\n            \n        buffer = io.BytesIO()\n        generated_image.save(buffer, format=\"PNG\")\n        image_bytes = buffer.getvalue()\n        \n        tasks[task_id][\"status\"] = \"COMPLETED\"\n        tasks[task_id][\"result\"] = image_bytes\n\n    except Exception as e:\n        print(f\"--- ASYNC TASK {task_id} FAILED ---\")\n        traceback.print_exc()\n        tasks[task_id][\"status\"] = \"FAILED\"\n        tasks[task_id][\"error\"] = str(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:24.186588Z","iopub.execute_input":"2025-12-03T21:48:24.187382Z","iopub.status.idle":"2025-12-03T21:48:24.194673Z","shell.execute_reply.started":"2025-12-03T21:48:24.187336Z","shell.execute_reply":"2025-12-03T21:48:24.193977Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from fastapi import Form, UploadFile, File, HTTPException\nfrom fastapi.responses import StreamingResponse, JSONResponse\nimport io  # Using `io` to match the working notebook\nfrom PIL import Image\nimport traceback\n\n@app.post(\"/generate\")\nasync def generate(\n    prompt: str = Form(...),\n    negative_prompt: str = Form(None),\n    seed: int = Form(None),\n    num_inference_steps: int = Form(40),\n    guidance_scale: float = Form(7.5),\n    \n    # Txt2Img params\n    height: int = Form(1024),\n    width: int = Form(1024),\n\n    # Img2Img params\n    strength: float = Form(0.7),\n    init_image: UploadFile = File(None),  # If present, triggers Img2Img\n\n    # ControlNet params\n    control_image: UploadFile = File(None),\n    controlnet_scale: float = Form(0.5),\n):\n    try:\n        controlnet_img = None\n        if control_image:\n            contents = await control_image.read()\n            controlnet_img = Image.open(io.BytesIO(contents)).convert(\"RGB\")\n        \n        # --- Img2Img Workflow ---\n        if init_image is not None:\n            if not USE_IMG2IMG:\n                raise RuntimeError(\"Received init_image, but notebook is in Txt2Img mode.\")\n            init_img = Image.open(io.BytesIO(await init_image.read())).convert(\"RGB\")\n            # NOTE: We assume generate_img2img_xl is also adapted similarly if you test it.\n            generated_image = generate_img2img_xl(\n                pipe=pipe, prompt=prompt, init_image=init_img, negative_prompt=negative_prompt,\n                strength=strength, num_inference_steps=num_inference_steps, guidance_scale=guidance_scale,\n                seed=seed, control_image=controlnet_img, controlnet_scale=controlnet_scale\n            )\n        \n        # --- Txt2Img Workflow ---\n        else:\n            if USE_IMG2IMG:\n                raise RuntimeError(\"Did not receive init_image, but notebook is in Img2Img mode.\")\n            \n            # Calling the generation function that mirrors the working notebook\n            generated_image = generate_txt2img_xl(\n                pipe=pipe, prompt=prompt, negative_prompt=negative_prompt, height=height, width=width,\n                num_inference_steps=num_inference_steps, guidance_scale=guidance_scale, seed=seed,\n                control_image=controlnet_img, controlnet_scale=controlnet_scale\n            )\n    except Exception as e:\n        traceback.print_exc()\n        return JSONResponse(status_code=500, content={\"error\": str(e), \"traceback\": traceback.format_exc()})\n\n    # --- [CRITICAL] ---\n    # USING THE EXACT RESPONSE LOGIC FROM THE WORKING NOTEBOOK\n    # `sage-t2i-counterfeit-xl-25/sage-t2i-counterfeit-xl-25.ipynb`\n    # ---\n    buffer = io.BytesIO()\n    generated_image.save(buffer, format=\"PNG\")\n    buffer.seek(0)\n    return StreamingResponse(buffer, media_type=\"image/png\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:27.358542Z","iopub.execute_input":"2025-12-03T21:48:27.359207Z","iopub.status.idle":"2025-12-03T21:48:27.372173Z","shell.execute_reply.started":"2025-12-03T21:48:27.359179Z","shell.execute_reply":"2025-12-03T21:48:27.371413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@app.post(\"/generate-async\")\nasync def generate_async(\n    background_tasks: BackgroundTasks,\n    prompt: str = Form(...),\n    negative_prompt: str = Form(None),\n    seed: int = Form(None),\n    num_inference_steps: int = Form(50),\n    guidance_scale: float = Form(7.5),\n    height: int = Form(1024),\n    width: int = Form(1024),\n    strength: float = Form(0.7),\n    init_image: UploadFile = File(None),\n    control_image: UploadFile = File(None),\n    controlnet_scale: float = Form(0.5),\n):\n    \"\"\"\n    Starts a generation job in the background and immediately returns a task ID.\n    \"\"\"\n    task_id = str(uuid.uuid4())\n    \n    # Read image contents now - NO conversion here, just raw bytes\n    init_image_bytes = await init_image.read() if init_image else None\n    control_image_bytes = await control_image.read() if control_image else None\n\n    # Store initial task state\n    tasks[task_id] = {\"status\": \"PENDING\"}\n\n    # Bundle all parameters for the background worker\n    params = {\n        \"prompt\": prompt, \"negative_prompt\": negative_prompt, \"seed\": seed,\n        \"num_inference_steps\": num_inference_steps, \"guidance_scale\": guidance_scale,\n        \"height\": height, \"width\": width, \"strength\": strength,\n        \"controlnet_scale\": controlnet_scale,\n        \"init_image_bytes\": init_image_bytes, \"control_image_bytes\": control_image_bytes\n    }\n    \n    # Add the long-running job to the background\n    background_tasks.add_task(run_generation_task, task_id, params)\n    \n    # Immediately return the task ID\n    return {\"task_id\": task_id, \"status\": \"PENDING\"}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:34.551002Z","iopub.execute_input":"2025-12-03T21:48:34.551285Z","iopub.status.idle":"2025-12-03T21:48:34.562450Z","shell.execute_reply.started":"2025-12-03T21:48:34.551264Z","shell.execute_reply":"2025-12-03T21:48:34.561756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"@app.get(\"/status/{task_id}\")\nasync def get_status(task_id: str):\n    \"\"\"\n    Polls for the status of a task. If completed, returns the image.\n    \"\"\"\n    task = tasks.get(task_id)\n    if not task:\n        raise HTTPException(status_code=404, detail=\"Task not found\")\n\n    status = task.get(\"status\")\n    \n    if status == \"COMPLETED\":\n        image_bytes = task.get(\"result\")\n        # Clean up the completed task to free memory\n        del tasks[task_id]\n        return Response(content=image_bytes, media_type=\"image/png\")\n    \n    elif status == \"FAILED\":\n        error_message = task.get(\"error\", \"Unknown error\")\n        # Clean up the failed task\n        del tasks[task_id]\n        raise HTTPException(status_code=500, detail=f\"Task failed: {error_message}\")\n        \n    else: # PENDING or PROCESSING\n        return {\"task_id\": task_id, \"status\": status}\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T22:12:27.959039Z","iopub.execute_input":"2025-12-03T22:12:27.959814Z","iopub.status.idle":"2025-12-03T22:12:27.966187Z","shell.execute_reply.started":"2025-12-03T22:12:27.959784Z","shell.execute_reply":"2025-12-03T22:12:27.965423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Download zrok v1.1.3 (latest)\n!wget https://github.com/openziti/zrok/releases/download/v1.1.3/zrok_1.1.3_linux_amd64.tar.gz\n!tar -xzf zrok_1.1.3_linux_amd64.tar.gz\n!chmod +x zrok","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:39.041973Z","iopub.execute_input":"2025-12-03T21:48:39.042570Z","iopub.status.idle":"2025-12-03T21:48:40.541453Z","shell.execute_reply.started":"2025-12-03T21:48:39.042545Z","shell.execute_reply":"2025-12-03T21:48:40.540616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Enable (automatic migration from 0.4)\n!./zrok enable --headless \"$zrok_token\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:46.352157Z","iopub.execute_input":"2025-12-03T21:48:46.352514Z","iopub.status.idle":"2025-12-03T21:48:53.058676Z","shell.execute_reply.started":"2025-12-03T21:48:46.352477Z","shell.execute_reply":"2025-12-03T21:48:53.057894Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!./zrok disable","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import uvicorn\nimport threading\n\ndef run_uvicorn():\n    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"info\")\n\n# Start in background thread\nthreading.Thread(target=run_uvicorn, daemon=True).start()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:56.341231Z","iopub.execute_input":"2025-12-03T21:48:56.342023Z","iopub.status.idle":"2025-12-03T21:48:56.348909Z","shell.execute_reply.started":"2025-12-03T21:48:56.341987Z","shell.execute_reply":"2025-12-03T21:48:56.347574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nimport time\n\ndef start_zrok_tunnel(port=8000):\n    # Start the tunnel\n    process = subprocess.Popen([\n        \"./zrok\", \"share\", \"public\", f\"localhost:{port}\", \"--headless\"\n    ], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n\n    # Give it a moment to start\n    time.sleep(3)\n\n    # Check agent status to get the URL\n    status_process = subprocess.run([\n        \"./zrok\", \"agent\", \"status\"\n    ], capture_output=True, text=True)\n\n    print(\"Agent Status:\")\n    print(status_process.stdout)\n\n    return process\n\n# Start the tunnel\ntunnel_process = start_zrok_tunnel(8000)\nprint(\"Zrok tunnel started! Check the agent status above for your public URL.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:48:59.475212Z","iopub.execute_input":"2025-12-03T21:48:59.475540Z","iopub.status.idle":"2025-12-03T21:49:02.583846Z","shell.execute_reply.started":"2025-12-03T21:48:59.475509Z","shell.execute_reply":"2025-12-03T21:49:02.583160Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!./zrok overview","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-03T21:49:05.973488Z","iopub.execute_input":"2025-12-03T21:49:05.974205Z","iopub.status.idle":"2025-12-03T21:49:06.488094Z","shell.execute_reply.started":"2025-12-03T21:49:05.974182Z","shell.execute_reply":"2025-12-03T21:49:06.487403Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import time\n\nprint(\"Server and zrok tunnel are running. Keeping the notebook alive...\")\n\ntry:\n    while True:\n        time.sleep(60)\nexcept KeyboardInterrupt:\n    print(\"Shutting down.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
